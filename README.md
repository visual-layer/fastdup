
<!-- PROJECT SHIELDS -->
<!--
*** I'm using markdown "reference style" links for readability.
*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).
*** See the bottom of this document for the declaration of the reference variables
*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.
*** https://www.markdownguide.org/basic-syntax/#reference-style-links
-->

[![PyPi][pypi-shield]][pypi-url]
[![PyPi][pypiversion-shield]][pypi-url]
[![PyPi][downloads-shield]][downloads-url]
[![Contributors][contributors-shield]][contributors-url]
[![License][license-shield]][license-url]

<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[pypi-shield]: https://img.shields.io/pypi/pyversions/fastdup?style=for-the-badge
[pypi-url]: https://pypi.org/project/fastdup/
[pypiversion-shield]: https://img.shields.io/pypi/v/fastdup?style=for-the-badge
[downloads-shield]: https://img.shields.io/pypi/dm/fastdup?style=for-the-badge
[downloads-url]: https://pypi.org/project/fastdup/
[contributors-shield]: https://img.shields.io/github/contributors/visual-layer/fastdup?style=for-the-badge
[contributors-url]: https://github.com/othneildrew/Best-README-Template/graphs/contributors
[license-shield]: https://img.shields.io/github/license/visual-layer/fastdup?style=for-the-badge
[license-url]: https://github.com/visual-layer/fastdup/blob/main/LICENSE

<!-- PROJECT LOGO -->
<br />
<div align="center">
  <a href="https://www.visual-layer.com">
    <img src="https://raw.githubusercontent.com/visual-layer/fastdup/main/gallery/fastdup%20newlogo%20trasparent2.png" alt="fastdup" width="400">
  </a>

<h3 align="center">Manage, Clean & Curate Visual Data - Fast and at Scale</h3>
An unsupervised and free tool for image and video dataset analysis.
  <p align="center">
    <br />
    <a href="https://visual-layer.readme.io/"><strong>Explore the docs Â»</strong></a>
    <br />
    <a href="https://visual-layer.readme.io/">Features</a>
    Â·
    <a href="https://github.com/visual-layer/fastdup/issues">Report Bug</a>
    Â·
    <a href="https://medium.com/@amiralush/large-image-datasets-today-are-a-mess-e3ea4c9e8d22">Read Blog</a>
    Â·
    <a href="https://visual-layer.readme.io/docs/getting-started">Quickstart</a>
    .
    <a href="https://visual-layer.com/">About us</a>
    <br />
    <br /> 
    <a href="https://visualdatabase.slack.com/join/shared_invite/zt-19jaydbjn-lNDEDkgvSI1QwbTXSY6dlA#/shared-invite/email">
    <img src="https://img.shields.io/badge/JOIN US ON SLACK-4A154B?style=for-the-badge&logo=slack&logoColor=white" alt="Logo">
    </a>
    <a href="https://www.linkedin.com/company/visual-layer/">
    <img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="Logo">
    </a>
    <a href="https://www.youtube.com/@visual-layer4035">
    <img src="https://img.shields.io/badge/-YouTube-black.svg?style=for-the-badge&logo=youtube&colorB=red" alt="Logo">
    </a>
  </p>
</div>




 ## Easily Manage, Clean & Curate Visual Data  at Scale
  
 **fastdup** by [Visual-Layer](https://visual-layer.com) is an unsupervised powerful free tool designed to rapidly extract valuable insights from your image & video datasets. Assisting you to increase your dataset quality and reduce your data operations costs at an unparalleled scale. 

From the authors of [XGBoost](https://github.com/apache/tvm), [Apache TVM](https://github.com/apache/tvm) & [Turi Create](https://github.com/apple/turicreate). 
<a href="https://www.linkedin.com/in/dr-danny-bickson-835b32">Danny Bickson</a>, <a href="https://www.linkedin.com/in/carlos-guestrin-5352a869/">Carlos Guestrin</a> & <a href="https://www.linkedin.com/in/amiralush">Amir Alush</a><br>

 
 <div>
   <img src="https://camo.githubusercontent.com/44da37f0f02bf104f0650fa5f2c754ed3f6166066c9210f31bacb9e63d60736e/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f70796261646765732e737667">
   <a href="https://pepy.tech/project/fastdup"><img src="https://static.pepy.tech/personalized-badge/fastdup?period=total&units=none&left_color=blue&right_color=orange&left_text=Downloads"></a>
   <a href="https://www.kaggle.com/graphlab/fastdup" rel="nofollow"><img src="https://camo.githubusercontent.com/a08ca511178e691ace596a95d334f73cf4ce06e83a5c4a5169b8bb68cac27bef/68747470733a2f2f6b6167676c652e636f6d2f7374617469632f696d616765732f6f70656e2d696e2d6b6167676c652e737667" alt="Open In Kaggle" data-canonical-src="https://kaggle.com/static/images/open-in-kaggle.svg" style="max-width: 100%;"></a>
<a href="https://join.slack.com/t/visualdatabase/shared_invite/zt-19jaydbjn-lNDEDkgvSI1QwbTXSY6dlA" rel="nofollow"><img src="https://camo.githubusercontent.com/8df26cc38dabf1035cddfbed79714744bb93785bc8341cb883fef4cdc412572d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f536c61636b2d3441313534423f6c6f676f3d736c61636b266c6f676f436f6c6f723d7768697465" alt="Slack" data-canonical-src="https://img.shields.io/badge/Slack-4A154B?logo=slack&amp;logoColor=white" style="max-width: 100%;"></a>
<a href="https://medium.com/@amiralush/large-image-datasets-today-are-a-mess-e3ea4c9e8d22" rel="nofollow"><img src="https://camo.githubusercontent.com/771af957ebd52645704462209592c7a0a359feaec816337fee900e4478278219/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d656469756d2d3132313030453f6c6f676f3d6d656469756d266c6f676f436f6c6f723d7768697465" alt="Medium" data-canonical-src="https://img.shields.io/badge/Medium-12100E?logo=medium&amp;logoColor=white" style="max-width: 100%;"></a>
<a href="https://share-eu1.hsforms.com/1POrgIy-hTSyMaOTQzgjqhgfglt8" rel="nofollow"><img src="https://camo.githubusercontent.com/5042565e9cc3a40bff3d9be7b59955d984831f594d38297b6efecf804e41b8f7/687474703a2f2f6269742e6c792f324d643972784d" alt="Mailing list" data-canonical-src="http://bit.ly/2Md9rxM" style="max-width: 100%;"></a>
</div>


<a href="https://bit.ly/3NJLxEe">Large Image Datasets Today are a Mess Blog </a> | <a href="https://www.youtube.com/watch?v=s6qamoFzyis&t=2s">Processing LAION400m Video </a><br>

## Introducing fastdup V1.0::tada:
- <font size=10> **Clean & simple API**:</font> The [new API](https://visual-layer.readme.io/docs/v1-api-engine-temp) is simpler to use <font size=5>  </font>
- <font size=10> **Native Windows support**:</font> Windows now has first-class, full feature support in fastdup <font size=5>  </font>
- <font size=10> **Amazing documentation**:</font> New and imporved fasdtdup [documentation](https://visual-layer.readme.io) <font size=5>  </font>
- <font size=10> **Sleek galleries**:</font> New and improved [galleries](https://visual-layer.readme.io/docs/visualizing-data) to get a better view of your data <font size=5>  </font>
- <font size=10> **Extensive labels support** :</font> <font size=5> Improved support for handling image and bounding box labels </font>
- <font size=10> **Additional image formats support**: </font> <font size=5>Appleâ€™s HEIC+HEIF, 16 bit grayscale TIFF </font>
- <font size=10> **Support for Python3.10** </font> <font size=5> </font>
- <font size=10> **Fully backcompatible to [old API](https://visual-layer.readme.io/docs/v02xx-api)** </font> <font size=5> </font>

<br>
 <h2> fastdup identifies these data issues:</h2>
 <div align="center" style="display:flex;flex-direction:column;">
  <a href="https://www.visual-layer.com">
    <img src="https://raw.githubusercontent.com/visual-layer/fastdup/main/gallery/issues.png" alt="fastdup" width="1000">
  </a>
 </div>


## What makes fastdup unique?
 - <font size=25> **Quality**:</font>  <font size=5> fastdup can assist you in reaching a high quality dataset by finding and removing anomalies and outliers from your datasets. Finding duplicate and near duplicate of images (&videos) and finding clusters of similarity at a large scale! </font>
 - <font size=25> **Cost** :</font> <font size=5> fastdup can also help you in reducing your data operations costs by facilitating the intelligent sampling of high-quality or novel datasets prior to labeling, as well as support the quality assessment of labeled data. </font>
 - <font size=25> **Scale**:</font> <font size=5> fastdup graph engine is written in C++ and is highly efficient and works in an incredible scale! Running locally on a CPU only machine and can handle up to 400M images on a single CPU machine! </font>

 <div align="center" style="display:flex;flex-direction:column;">
  <a href="https://www.visual-layer.com">
    <img src="https://raw.githubusercontent.com/visual-layer/fastdup/main/gallery/features.png" alt="fastdup" width="1000">
  </a>
 </div>

<div align="center" style="display:flex;flex-direction:column;">
<h2> Get insights on your data with just 3 lines of code:</h2>
<div align="center" style="display:flex;flex-direction:column;">
 <a href="https://www.youtube.com/watch?v=s6qamoFzyis&t=2s">
    <img src="https://raw.githubusercontent.com/visual-layer/fastdup/main/gallery/fastdup_run_v1.0.gif" alt="fastdup" width="800">
  </a>
  
  <div align="left" style="display:flex;flex-direction:column;">
  

## Installation 
```python
# upgrade pip to its latest version
pip install -U pip

# install fastdup
pip install fastdup
    
# Alternatively, use explicit python version (XX)
python3.XX -m pip install fastdup 
```
- **Supported Python**: 3.7, 3.8, 3.9, 3.10
- **Supported OS**: Windows 10, 11 and 2019 Server (Native), Windows WSL, Ubuntu (20.04, 18.04), Mac OSX 10+ (Intel and M1 CPUs), Amazon Linux 2, CentOS 7, RedHat 4.8.
- [Full installation instructions are here](https://visual-layer.readme.io/docs/installation)

## Running fastdup
```python
import fastdup

fd = fastdup.create(work_dir, images_dir)
fd.run(nearest_neighbors_k=5, cc_threshold=0.96)

fd.vis.duplicates_gallery()     #create a visual gallery of found duplicates
fd.vis.outliers_gallery()       #create a visual gallery of anomalies
fd.vis.component_gallery()     #create visualiaiton of connected components
fd.vis.stats_gallery()          #create visualization of images stastics (for example blur)
```

![alt text](https://github.com/visual-layer/fastdup/blob/main/gallery/gifl_fastdup_quickstart_V1.gif?raw=true)
*Working on the Oxford Pet Dataset. Detecting identical pairs, similar-pairs (search) and outliers*

## Getting started examples 
- [Quick dataset analysis](https://visual-layer.readme.io/docs/getting-started) <a target="_blank" href="https://colab.research.google.com/drive/18gbpq8A62KAjJolCuRnOAmJCRGT1Vu1J#scrollTo=pN6wiKBax7Pa">  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
- [Cleaning and preparing a dataset](https://visual-layer.readme.io/docs/abc)  <a target="_blank" href="https://colab.research.google.com/drive/1NBTD_Z5beSlumQOqDPdF2UzrhdEf0uxC">  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
- [Preparing an image dataset for training](https://visual-layer.readme.io/docs/analyzing-labeled-images)  <a target="_blank" href="https://colab.research.google.com/drive/1LMbwD5QcXqqk8HSGfHu8m5o5KvG7MfGc">  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
- [Preparing an object dataset for training](https://visual-layer.readme.io/docs/objects-and-bounding-boxes)  <a target="_blank" href="https://colab.research.google.com/drive/1MwxalEbILkSUt3NXZRhc9bWjfIGFbC6p">  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

## Full documentation
- [Full documentation is here](https://visual-layer.readme.io) 
- [Older API documentation](https://visual-layer.readme.io/docs/v02xx-api)

## Support and feature requests 
<a href="https://bit.ly/3OLojyT">Join our Slack channel</a>    <a href="https://join.slack.com/t/visualdatabase/shared_invite/zt-19jaydbjn-lNDEDkgvSI1QwbTXSY6dlA" rel="nofollow"><img src="https://camo.githubusercontent.com/8df26cc38dabf1035cddfbed79714744bb93785bc8341cb883fef4cdc412572d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f536c61636b2d3441313534423f6c6f676f3d736c61636b266c6f676f436f6c6f723d7768697465" alt="Slack" data-canonical-src="https://img.shields.io/badge/Slack-4A154B?logo=slack&amp;logoColor=white" style="max-width: 100%;"></a>
    
    
<a href="https://visual-layer.readme.io/discuss">Have a question? Use our discussion forum</a> 

## ðŸš€ fastdup enterprise early access
 Sign up at <a href="https://www.visual-layer.com">Visual Layer</a>


## What our users think about fastdup: 
<div align="center" style="display:flex;flex-direction:column;">
  <a href="https://www.visual-layer.com">
    <img src="https://raw.githubusercontent.com/visual-layer/fastdup/main/gallery/tweet.png" alt="fastdup" width="1000">
  </a>
<a href="https://www.visual-layer.com">
    <img src="https://raw.githubusercontent.com/visual-layer/fastdup/main/gallery/tweet2.png" alt="fastdup" width="1000">
  </a>
 </div>

## User community contributions
- [Master Data Integrity to Clean Your Computer Vision Datasets
](https://towardsdatascience.com/master-data-integrity-to-clean-your-computer-vision-datasets-df432cf9e596)
- [fastdup: A Powerful Tool to Manage, Clean & Curate Visual Data at Scale on Your CPU - For Free.](https://dicksonneoh.com/portfolio/fastdup_manage_clean_curate/)
- [Clean Up Your Digital Life: Simplify Your Photo Organization and Say Goodbye to Photo Clutter](https://dicksonneoh.com/blog/clean_up_your_digital_life/)

## License questions
Please reach us at info@visual-layer.com 

## Disclaimer
<details>
  <summary><b>Usage Tracking</b></summary>

We have added experimental crash report collection, using [sentry.io](https://github.com/getsentry/). It does not collect user data other than anonymized IP address data, and it only logs fastdup library's own actions. We do NOT collect folder name, user name, image names, image content only aggregate performance statistics like total number of images, average runtime per image, total free memory, total free disk space, number of cores etc. Collecting fastdup crashes will help us improve stability. 

The code for the data collection is found [here](./src/sentry.hpp). On MAC we use [Google crashpad](https://chromium.googlesource.com/crashpad/crashpad). 

It is always possible to opt out of the experimental crash report collection via either of the following two options:
- Define an environment variable called `SENTRY_OPT_OUT`
- or run() with `turi_param='run_sentry=0'`

</details>

## About Visual-Layer
<a href="https://visual-layer.com">Visual Layer Inc.</a><br>

</div>

